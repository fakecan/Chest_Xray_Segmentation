{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fc188a6-5ab8-4ba2-b042-774e480b1439",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Starting point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b92781d-d10b-4ecc-af0c-3240fa5cf773",
   "metadata": {},
   "source": [
    "Input: (256, 256, 3) Chest X-ray image 566개\n",
    "<br>\n",
    "Label: 좌우 lung 마스킹되어 있는 흑백 이미지 566개\n",
    "<br><br>\n",
    "이미지 기준 좌측 폐: Right lung\n",
    "이미지 기준 우측 폐: Left lung\n",
    "<br>\n",
    "※ Task<br>\n",
    "&nbsp;&nbsp;&nbsp;    - Left lung, Right lung 분할(2 classes + 1 class(background)) <br>\n",
    "&nbsp;&nbsp;&nbsp;    - 훈련 & 추론 + 후처리(보간법) 노이즈 제거(예측 성능 ↑)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fabd0b-70f9-413f-829b-39cae4f9a749",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 데이터 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4351c35e-e4f0-4e42-9a7c-34a62f85e542",
   "metadata": {},
   "source": [
    "data <br>\n",
    "&nbsp;&nbsp;    └ image/ <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;        resize_CHNCXR_0001_0.png <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;        resize_CHNCXR_0002_0.png <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;        resize_CHNCXR_0003_0.png <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;        ... <br>\n",
    "&nbsp;&nbsp;    └ label/                     -> 사전 작업 후에는 사용하지 않습니다. <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;        resize_CHNCXR_0001_0.png <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;        resize_CHNCXR_0002_0.png <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;        resize_CHNCXR_0003_0.png <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;        ...    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6454af-0da1-4586-84f9-0d4b3e508e2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 사전 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c670677-bebb-42ee-89fa-cab07039984f",
   "metadata": {},
   "source": [
    "label 폴더의 마스킹 이미지를 각각 좌측 폐('label_rl/l/*'), 우측 폐'label_rl/r/*'로 분할하여 어노테이션 처리하였습니다.<br>\n",
    "추후 작업 시 라벨링을 배경: 0, 좌측 폐: 1, 우측 폐: 2로 하고 다시 one-hot encoding 작업으로 분할하여 진행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f19d2cd-9fd2-4619-a896-01b1829d5652",
   "metadata": {},
   "source": [
    "# 2. Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "934d9beb-41ae-49ad-93fb-cc77f6c1e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "import statistics\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Add, Input, Dense, Conv2D, Flatten, MaxPool2D, UpSampling2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose, Concatenate, BatchNormalization\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce51c14-f320-4b10-a1d7-390b84f52667",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67cb9992-f114-4f26-8da2-a6033e7910ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "N_CLASSES = 2\n",
    "EPOCHS = 80\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f8401073-2b70-49d4-af14-c384366929bc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input, Label making\n",
    "input_path = './data/image/'\n",
    "input_files = os.listdir(input_path)\n",
    "label_path = './data/label/'\n",
    "label_files = os.listdir(label_path)\n",
    "half_width = int(IMG_WIDTH/2)\n",
    "\n",
    "X_all = np.zeros((len(input_files), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\n",
    "                  dtype=np.uint8) # Input image\n",
    "y_all = np.zeros((len(label_files), IMG_HEIGHT, IMG_WIDTH, N_CLASSES),\n",
    "                  dtype=np.bool)  # Label(Mask)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for input_file in input_files:\n",
    "    img_path = input_path + input_file\n",
    "    img = imread(img_path)[:,:,:IMG_CHANNELS]\n",
    "    X_all[count] = img\n",
    "    # print(img.shape)\n",
    "\n",
    "for i, label_file in enumerate(label_files):\n",
    "    label_img = cv2.imread(label_path + label_file, cv2.IMREAD_GRAYSCALE)\n",
    "    cnt, labels = cv2.connectedComponents(label_img)\n",
    "    mass = np.zeros_like(labels)  \n",
    "    \n",
    "    for label_cnt, j in enumerate(range(cnt)):\n",
    "        mass[labels==j] = label_cnt + 3\n",
    "    \n",
    "    left_side = np.unique(mass[:, :half_width], return_counts=True)\n",
    "    l_idx = left_side[0]\n",
    "    l_value = left_side[1]\n",
    "    l_sort = l_value.argsort()\n",
    "    \n",
    "    right_side = np.unique(mass[:, half_width:], return_counts=True)\n",
    "    r_idx = right_side[0]\n",
    "    r_value = right_side[1]\n",
    "    r_sort = r_value.argsort()\n",
    "\n",
    "    l_re_sort = l_idx[l_sort][::-1]\n",
    "    r_re_sort = r_idx[r_sort][::-1]\n",
    "    \n",
    "    mass[mass==l_re_sort[1]] = 1\n",
    "    mass[mass==r_re_sort[1]] = 2\n",
    "    mass[((mass != 1) & (mass != 2))] = 0\n",
    "    \n",
    "    mass = np.expand_dims(mass, axis=-1)\n",
    "    mass = tf.keras.utils.to_categorical(y=mass, num_classes=3)\n",
    "\n",
    "    left_mask = np.expand_dims(mass[:,:,1], axis=-1)\n",
    "    right_mask = np.expand_dims(mass[:,:,2], axis=-1)\n",
    "    \n",
    "    mask = np.concatenate((left_mask, right_mask), axis=2)\n",
    "    # print(mask.shape)\n",
    "    \n",
    "    y_all[count] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f1851910-f527-4441-b18e-755f392ff161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_all shape:  (566, 256, 256, 3)\n",
      "y_all shape:  (566, 256, 256, 2)\n",
      "X_train shape:  (361, 256, 256, 3)\n",
      "X_valid shape:  (91, 256, 256, 3)\n",
      "X_test shape:  (114, 256, 256, 3)\n",
      "y_train shape:  (361, 256, 256, 2)\n",
      "y_valid shape:  (91, 256, 256, 2)\n",
      "y_test shape:  (114, 256, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "print('X_all shape: ', X_all.shape)\n",
    "print('y_all shape: ', y_all.shape)\n",
    "\n",
    "X_all = X_all.astype('float32') / 255.\n",
    "y_all = y_all.astype('float32')\n",
    "\n",
    "# data slicing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('X_valid shape: ', X_valid.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('y_valid shape: ', y_valid.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c8d9e4-6296-45ab-91bf-e11d2398b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plotTrainData(a,b,c):\n",
    "#     for i in range(3):\n",
    "#         ix = np.random.randint(0, len(a))\n",
    "#         plt.subplot(1,2,1)\n",
    "#         plt.title(\"X_\" + c)\n",
    "#         plt.imshow(a[ix])\n",
    "#         plt.axis('off')\n",
    "#         plt.subplot(1,2,2)\n",
    "#         plt.title(\"y_\" + c)\n",
    "#         plt.imshow(np.squeeze(b[ix]))#, 'gray')\n",
    "#         plt.axis('off')\n",
    "#         plt.show()\n",
    "        \n",
    "# plotTrainData(X_train,y_train, 'train')\n",
    "# plotTrainData(X_valid,y_valid, 'valid')\n",
    "# plotTrainData(X_test,y_test, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e1aced-0e47-468c-9168-aacf64c9b9e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Modeling(U-Net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a8797d-0523-4f2e-b9d2-4db243653abb",
   "metadata": {
    "tags": []
   },
   "source": [
    "![대체 텍스트](https://www.renom.jp/notebooks/tutorial/image_processing/u-net/unet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394ee53d-04ca-4591-a996-e1ac1e4b0193",
   "metadata": {},
   "source": [
    "## 4-1. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f0eba74-7c1b-42a0-9f17-d3932072d07b",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kwbr1FaF9dUL"
   },
   "outputs": [],
   "source": [
    "# U-Net model\n",
    "# 신경망의 끝단을 MLP가 아닌 CNN을 채택함으로서 기존의 MLP에서의 Flatten으로\n",
    "# 인한 이미지 특성의 보존이 약해지는 것을 보완하고자 하였다.\n",
    "# Input: (H, W, C)\n",
    "# Output: FCN을 사용하여,\n",
    "#         합성곱(분류 클래스 개수, kernel_size, activation)\n",
    "# 이미지 해상도를 Maxpooling(<-> Upsampling)하여 줄여나가다(채널은 증가)\n",
    "# Upsampling으로 작아진 해상도를 늘리며 주변 픽셀을 예측해 값을 채운다.\n",
    "# 가장 특징적인 점은 Skip connection 기법으로 은닉층을 거칠수록 피쳐맵이 형이상학적인 모양을 띄어가는데\n",
    "# 그 이전에 초반 레이어 단에서의 비교적 단순한 피쳐맵(수평선, 수직선, 곡선같은 모양)을 Concatenate하여\n",
    "# 후반 레이어 단에 연결시켜 가중치를 더하는 역할을 한다.\n",
    "def unet(input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPool2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPool2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPool2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    pool4 = MaxPool2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    \n",
    "    up6 = Concatenate()([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4])\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    \n",
    "    up7 = Concatenate()([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3])\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    \n",
    "    up8 = Concatenate()([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2])\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    \n",
    "    up9 = Concatenate()([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1])\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "\n",
    "    conv10 = Conv2D(N_CLASSES, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    return Model(inputs=[inputs], outputs=[conv10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd2d60a-6976-4d42-970b-8eebaec30802",
   "metadata": {},
   "source": [
    "## 4-2. Compile & Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c17f8567-2090-44d7-8978-a639867c36c6",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fgjDwo9DxORy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loss function 계산\n",
    "# dice coefficient영역이 얼마나 겹치는지를(교집합) 판단하여 오차를 계산한다.(=F1 score)\n",
    "def dice_coef(y_true, y_pred):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    return (2. * intersection + 1) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + 1)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c9ebc5-0971-422f-87f8-77ba6496fe92",
   "metadata": {},
   "source": [
    "### 모델이 존재하면 로드와 컴파일만 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "67a5cbb2-fe88-492d-b854-2a2b2ea3c1c9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 256, 256, 32) 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 32) 9248        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 256, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 128, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 64) 18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 64) 36928       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 64) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 128)  147584      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 128)  512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 128)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 256)  590080      batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 256)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 512)  2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 512)  2359808     batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 512)  2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 32, 32, 256)  524544      batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 512)  0           conv2d_transpose[0][0]           \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 256)  1179904     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 256)  590080      batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 256)  1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 64, 64, 128)  131200      batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 256)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 128)  295040      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 128)  147584      batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 64) 32832       batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 128 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 64) 73792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 128, 128, 64) 256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 64) 36928       batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128, 128, 64) 256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 256, 256, 32) 8224        batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 64) 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 256, 32) 18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 256, 256, 32) 128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 256, 32) 9248        batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 256, 256, 32) 128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 3)  99          batch_normalization_17[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 7,771,939\n",
      "Trainable params: 7,766,051\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('./model/20211129-151140.h5', custom_objects={'dice_coef':dice_coef, 'dice_coef_loss':dice_coef_loss})\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss=dice_coef_loss,\n",
    "              optimizer=sgd,\n",
    "              metrics=[dice_coef])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f95409-c006-49a4-ab77-12a4da5e6075",
   "metadata": {},
   "source": [
    "### If not model fited.. execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cfd1b64-892d-4f7f-8c6b-3dc57cdb3d29",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_h5_path:  ./model/20211129-151140.h5\n",
      "Model already saved and loaded..\n"
     ]
    }
   ],
   "source": [
    "model_h5_path = './model/20211129-151140.h5'\n",
    "print(f\"model_h5_path:  {model_h5_path}\")\n",
    "\n",
    "if os.path.isfile(model_h5_path):\n",
    "    print(\"Model already saved and loaded..\")\n",
    "\n",
    "else: # model.fit\n",
    "    print(\"Model initial setting(compile & fit) start..\")\n",
    "    \n",
    "    # earlystopping = EarlyStopping(monitor='val_loss', # 'dice_coef_loss를 custom 적용.. 찾기'\n",
    "    #                               patience=10)\n",
    "    # modelcheckpoint = ModelCheckpoint(f\"./model_ckpt/{time.strftime('%Y%m%d-%H%M%S')}.h5\",\n",
    "    #                                   monitor='val_loss',\n",
    "    #                                   verbose=1,\n",
    "    #                                   save_best_only=True,\n",
    "    #                                   mode='auto')\n",
    "\n",
    "    # build the model\n",
    "    model = unet()\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss=dice_coef_loss,\n",
    "                  optimizer=sgd,\n",
    "                  metrics=[dice_coef])\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # FIT THE MODEL - OPTIMIZATION\n",
    "    hist = model.fit(X_train, y_train,\n",
    "                     validation_data=(X_valid, y_valid),\n",
    "                     epochs=EPOCHS,\n",
    "                     batch_size=BATCH_SIZE,\n",
    "                     verbose=1)\n",
    "    #                  callbacks=[modelcheckpoint, earlystopping])\n",
    "\n",
    "    runtime = str(datetime.timedelta(seconds=time.time()-start)).split(\".\")\n",
    "    runtime = runtime[0]\n",
    "    print(f\"Fitting Runtime: {runtime}\")\n",
    "\n",
    "    # model.save(f\"./model/{time.strftime('%Y%m%d-%H%M%S')}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46adfa57-cb3f-4e1e-8cf3-05cf89aeed7c",
   "metadata": {},
   "source": [
    "## 4-3. Fit Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "771cff3a-201f-461c-abf5-1f8e42013f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(model_h5_path):\n",
    "    pass\n",
    "\n",
    "else:\n",
    "    # 학습과정 살펴보기\n",
    "    fig, loss_ax = plt.subplots()\n",
    "\n",
    "    acc_ax = loss_ax.twinx()\n",
    "\n",
    "    loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "    acc_ax.plot(hist.history['dice_coef'], 'b', label='train dice_coef')\n",
    "    acc_ax.plot(hist.history['val_dice_coef'], 'g', label='val dice_coef')\n",
    "\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    acc_ax.set_ylabel('dice_coef')\n",
    "\n",
    "    loss_ax.legend(loc='upper left')\n",
    "    acc_ax.legend(loc='lower left')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1296297b-60fa-41bc-8040-c60b90d3763a",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_yaOK2b8wita"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (361, 256, 256, 3)\n",
      "X_valid (91, 256, 256, 3)\n",
      "X_test (114, 256, 256, 3)\n",
      "y_train (361, 256, 256, 3)\n",
      "y_valid (91, 256, 256, 3)\n",
      "y_test (114, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print('X_train', X_train.shape)\n",
    "print('X_valid', X_valid.shape)\n",
    "print('X_test', X_test.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('y_valid', y_valid.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752081a1-0789-47fe-bc4c-f850238e48d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf240",
   "language": "python",
   "name": "tf240"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
